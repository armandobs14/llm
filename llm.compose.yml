services:
  ollama:
    labels:
        - "traefik.enable=true"
        - "traefik.http.routers.ollama.rule=Host(`ollama.localhost`)"
        - "traefik.http.services.ollama.loadbalancer.server.port=11434"
        - "traefik.http.routers.ollama.entrypoints=web"
    image: ollama/ollama
    container_name: ollama
    ports:
      - 11434:11434
    volumes:
      - .volumes/ollama:/root/.ollama
  neo4j:
    labels:
        - "traefik.enable=true"
        - "traefik.http.routers.neo4j.rule=Host(`neo4j.localhost`)"
        - "traefik.http.routers.neo4j.service=neo4j-service"
        - "traefik.http.services.neo4j-service.loadbalancer.server.port=7474"
        - "traefik.http.routers.neo4j.entrypoints=web"
    image: neo4j:5.18.1
    container_name: neo4j
    ports:
      - 7687:7687
    #   - 7474:7474
    volumes:
      - .volumes/neo4j/data:/data
      - .volumes/neo4j/conf:/var/lib/neo4j/conf
    environment:
      - NEO4JLABS_PLUGINS=["apoc"]
      - NEO4J_AUTH=neo4j/12345678
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget --no-verbose --tries=1 --spider localhost:7474 || exit 1"
        ]
  jupyterlab:
    labels:
        - "traefik.enable=true"
        - "traefik.http.routers.jupyter.rule=Host(`jupyter.localhost`)"
        - "traefik.http.services.jupyter.loadbalancer.server.port=8888"
        - "traefik.http.routers.jupyter.entrypoints=web"
    image: jupyter/minimal-notebook
    container_name: jupyterlab
    # ports:
    #   - 8888:8888
    user: "${UID}:${GID}"
    command: "start-notebook.sh \
        --NotebookApp.token=''"
    volumes:
      - .volumes/notebooks:/home/jovyan/work
    depends_on:
      - neo4j
      - ollama
  ui:
    labels:
        - "traefik.enable=true"
        - "traefik.http.routers.ui.rule=Host(`ui.localhost`)"
        - "traefik.http.services.ui.loadbalancer.server.port=8080"
        - "traefik.http.routers.ui.entrypoints=web"
    image: ghcr.io/open-webui/open-webui:main
    container_name: ui
    volumes:
      - .volumes/ui:/app/backend/data
    # ports:
    #   - 3000:8080
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      - ollama
